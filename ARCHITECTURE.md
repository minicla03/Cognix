# Architettura Q-AmodelAI

Documentazione tecnica dettagliata dell'architettura del sistema Q-AmodelAI.

---

## ðŸ“‹ Indice

1. [Panoramica](#panoramica)
2. [Architettura a Livelli](#architettura-a-livelli)
3. [Flusso dei Dati](#flusso-dei-dati)
4. [Componenti Chiave](#componenti-chiave)
5. [Pattern e Principi](#pattern-e-principi)
6. [Tecnologie Utilizzate](#tecnologie-utilizzate)

---

## Panoramica

Q-AmodelAI Ã¨ un sistema RAG (Retrieval-Augmented Generation) modulare che implementa un'architettura multi-layer per la gestione di documenti, l'elaborazione di query e la generazione di contenuti educativi.

### Caratteristiche Architetturali

- **ModularitÃ **: Componenti ben separati con responsabilitÃ  chiare
- **ScalabilitÃ **: Supporto per multiple sessioni e utenti
- **Persistenza**: Dual-storage (MongoDB + Redis) per dati persistenti e temporanei
- **EstensibilitÃ **: Pattern Strategy per aggiungere nuovi loader e tool
- **Multilingua**: Supporto nativo per 5 lingue

---

## Architettura a Livelli

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PRESENTATION LAYER (Streamlit)          â”‚
â”‚  - notebook_page.py (gestione notebook)         â”‚
â”‚  - pages/chat.py (interfaccia chat)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            RAG LOGIC LAYER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   AGENTS     â”‚  â”‚    TOOLS     â”‚            â”‚
â”‚  â”‚ - routing    â”‚  â”‚ - QATool     â”‚            â”‚
â”‚  â”‚ - summarizer â”‚  â”‚ - Flashcard  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ - Quiz       â”‚            â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  INGESTION   â”‚  â”‚   MEMORY     â”‚            â”‚
â”‚  â”‚ - PDF/CSV    â”‚  â”‚ - ChatMgr    â”‚            â”‚
â”‚  â”‚ - Chunking   â”‚  â”‚ - Notebook   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PERSISTENCE LAYER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   MongoDB    â”‚  â”‚    Redis     â”‚            â”‚
â”‚  â”‚ - Users      â”‚  â”‚ - Sessions   â”‚            â”‚
â”‚  â”‚ - Notebooks  â”‚  â”‚ - Chat Hist  â”‚            â”‚
â”‚  â”‚ - Flashcards â”‚  â”‚              â”‚            â”‚
â”‚  â”‚ - Quizzes    â”‚  â”‚              â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          EXTERNAL SERVICES                      â”‚
â”‚  - Ollama (LLM - Llama3)                        â”‚
â”‚  - ChromaDB (Vector Store)                      â”‚
â”‚  - HuggingFace (Embeddings)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Flusso dei Dati

### 1. Ingestion Flow (Caricamento Documenti)

```
User Upload (PDF/CSV)
    â†“
DocumentLoaderStrategy (pattern Strategy)
    â†“
Document Parsing
    â†“
RecursiveCharacterTextSplitter
    â”œâ”€ chunk_size: 600
    â””â”€ chunk_overlap: 200
    â†“
HuggingFace Embeddings
    â””â”€ paraphrase-multilingual-MiniLM-L12-v2
    â†“
ChromaDB Vector Store
    â””â”€ collection: user_{user_id}_notebook_{notebook_id}
```

### 2. Query Flow (Elaborazione Query)

```
User Query
    â†“
routing_agent (LLM-based classification)
    â”œâ”€ Analizza intento
    â””â”€ Seleziona tool appropriato
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QATool â”‚ FlashcardToolâ”‚ QuizTool â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Similarity Search (ChromaDB)
    â”œâ”€ k=10 documenti
    â””â”€ similarity_threshold=0.75
    â†“
LLM Generation (Ollama Llama3)
    â”œâ”€ Context: documenti rilevanti
    â”œâ”€ Query: domanda utente
    â””â”€ Chat history: riassunto conversazione
    â†“
Response + Sources
    â†“
ChatHistory (Redis) + Summarization (se necessario)
```

### 3. Memory Management Flow

```
Chat Messages
    â†“
ChatManager
    â”œâ”€ Salva in Redis (temporaneo)
    â””â”€ Ogni N messaggi â†’ Summarization
    â†“
summarizer_agent
    â””â”€ Genera riassunto conversazione
    â†“
MongoDB (persistente)
    â””â”€ Aggiorna metadata notebook
```

---

## Componenti Chiave

### 1. rag_logic/agents/

#### routing_agent.py
**ResponsabilitÃ **: Classificazione automatica delle query

```python
def router_agent(user_query, language_hint="italian") -> str:
    """
    Returns: "QA_TOOL" | "FLASHCARD_TOOL" | "QUIZ_TOOL"
    """
```

**Funzionamento**:
- Utilizza Ollama (Llama3) per analizzare l'intento
- Temperature bassa (0.1) per classificazione deterministica
- Prompt engineering per output strutturato

#### summarizer_agent.py
**ResponsabilitÃ **: Riassunto conversazioni lunghe

**Trigger**: Quando la chat supera una certa lunghezza

---

### 2. rag_logic/tools/

Implementano `IToolStrategy` (pattern Strategy)

#### QATool
- **Input**: query utente + riassunto chat
- **Output**: risposta + documenti fonte
- **Parametri**:
  - `max_sources=3`: massimo documenti da utilizzare
  - `similarity_threshold=0.75`: soglia minima similaritÃ 

#### FlashcardTool
- **Output**: Set di flashcard (domanda/risposta)
- **Formato**: JSON strutturato

#### QuizTool
- **Output**: Quiz a scelta multipla
- **Formato**: JSON con domanda, opzioni, risposta corretta

---

### 3. rag_logic/ingestion/

#### DocumentLoaderStrategy (Pattern Strategy)
```python
IDocumentLoader (Interface)
    â”œâ”€ PDFLoader
    â””â”€ CSVLoader
```

**EstensibilitÃ **: Aggiungere nuovi loader implementando `IDocumentLoader`

#### IngestionFlow
**ResponsabilitÃ **: Orchestrazione processo ingestion

**Steps**:
1. Load document via strategy
2. Split in chunks
3. Generate embeddings
4. Store in ChromaDB

---

### 4. rag_logic/memory/

#### ChatManager
**ResponsabilitÃ **: Gestione cronologia conversazioni

**Funzioni principali**:
- `add_message()`: aggiunge messaggio a storia
- `get_history()`: recupera storia chat
- `summarize_if_needed()`: trigger summarization

**Storage**: Redis (temporaneo, performance)

#### NotebookManager
**ResponsabilitÃ **: Gestione notebook utente

**Funzioni principali**:
- `create_notebook()`: crea nuovo notebook
- `get_notebooks()`: lista notebook utente
- `update_metadata()`: aggiorna info notebook

**Storage**: MongoDB (persistente)

---

### 5. persistence/

#### Pattern Repository
Astrazione accesso dati con interfacce:
- `IUserRepository`
- `IChatRepository`
- `INotebookRepository`
- `IFlashcardRepository`
- `IQuizRepository`

#### MongoDB Implementation
**Collections**:
- `users`: dati utente
- `notebooks`: metadata notebook
- `flashcards`: flashcard generate
- `quizzes`: quiz generati

**Vantaggi**:
- Schema flessibile per documenti
- Queries complesse su metadata
- Persistenza a lungo termine

#### Redis Implementation
**Keys Pattern**: `chat:{chat_id}:messages`

**Vantaggi**:
- Accesso ultra-rapido
- TTL automatico per cleanup
- Ideale per sessioni temporanee

---

### 6. presentation/

#### Streamlit Architecture
**Multi-page app**:
- `notebook_page.py`: Home page
- `pages/chat.py`: Chat interface

**Session State**:
- `current_notebook_id`
- `chat_manager`
- `messages`

**Layout**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docs   â”‚  Chat   â”‚  Tools  â”‚
â”‚ Upload  â”‚ History â”‚ Export  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pattern e Principi

### Design Patterns Utilizzati

1. **Strategy Pattern**
   - Loader per documenti
   - Tools per elaborazione query
   
2. **Repository Pattern**
   - Astrazione layer persistenza
   - Facile switch tra DB
   
3. **Singleton Pattern**
   - Connection managers (MongoDB, Redis)
   - Evita connessioni multiple
   
4. **Factory Pattern**
   - Creazione embeddings
   - Inizializzazione chains

### Principi SOLID

- **Single Responsibility**: Ogni classe ha una responsabilitÃ  ben definita
- **Open/Closed**: Estensibile via Strategy (nuovi loader/tools)
- **Dependency Inversion**: Dipendenze su interfacce, non implementazioni

---

## Tecnologie Utilizzate

### Core Technologies

| Tecnologia | Versione | Utilizzo |
|------------|----------|----------|
| Python | 3.10+ | Linguaggio principale |
| LangChain | Latest | Framework RAG |
| Streamlit | Latest | Web UI |
| MongoDB | 5.0+ | Database persistente |
| Redis | 6.0+ | Cache & sessions |

### AI/ML Stack

| Componente | Modello/Servizio | Scopo |
|------------|------------------|-------|
| LLM | Ollama Llama3 | Generazione risposte |
| Embeddings | HuggingFace MiniLM-L12-v2 | Rappresentazione semantica |
| Vector DB | ChromaDB | Similarity search |

### Libraries

```python
# RAG & LLM
langchain>=0.1.0
langchain-ollama
langchain-chroma
langchain-huggingface

# Database
pymongo>=4.0
redis>=4.0

# ML & NLP
sentence-transformers
transformers

# Web & UI
streamlit>=1.20

# Utils
python-dotenv
```

---

## Configurazione

### Environment Variables

```bash
# MongoDB
MONGO_HOST=localhost
MONGO_PORT=27017
MONGO_DB=rag_system
MONGO_USER=<optional>
MONGO_PASSWORD=<optional>

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=<optional>
REDIS_DB=0

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3:latest
```

### Directories

```
data/
â”œâ”€â”€ vectorstores/          # ChromaDB collections
â””â”€â”€ uploads/               # Temporary file uploads

docs/                      # User uploaded documents

chroma_db/                 # Legacy vector store
```

---

## Performance & Scalability

### Ottimizzazioni Implementate

1. **Chunking Efficiente**
   - Chunk size ottimizzato: 600 caratteri
   - Overlap: 200 caratteri (contesto)

2. **Caching**
   - Redis per chat history
   - Evita query ripetitive a MongoDB

3. **Similarity Threshold**
   - Filtraggio documenti poco rilevanti
   - Riduce context size per LLM

4. **Summarization**
   - Compressione storia conversazioni
   - Mantiene context window gestibile

### Limitazioni Attuali

- **Single LLM Instance**: Ollama locale (no load balancing)
- **No Horizontal Scaling**: Architettura single-process
- **Vector Store**: ChromaDB locale (non distribuito)

### Possibili Miglioramenti

1. **ScalabilitÃ **
   - Deploy LLM su cluster
   - Vector DB distribuito (Pinecone, Weaviate)
   - Load balancer per Streamlit

2. **Performance**
   - Async processing per ingestion
   - Batch embeddings
   - Cache risultati query frequenti

3. **Monitoraggio**
   - Logging strutturato
   - Metrics (latency, usage)
   - Error tracking

---

## Testing

### Test Suite Structure

```
test/
â””â”€â”€ unit/
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ test_router.py
    â”‚   â””â”€â”€ test_summarizer.py
    â”œâ”€â”€ ingestion/
    â”‚   â””â”€â”€ test_ingestion.py
    â””â”€â”€ tools/
        â””â”€â”€ test.py
```

### Evaluation Metrics

Il sistema include valutazione automatica con:
- **BLEU**: SimilaritÃ  n-gram
- **ROUGE-L**: Longest common subsequence
- **F1 Score**: Precision & Recall
- **Semantic Similarity**: Cosine similarity embeddings

---

## Sicurezza

### Considerazioni

1. **Input Validation**: Validazione documenti caricati
2. **SQL/NoSQL Injection**: Parametrizzazione query
3. **Secrets Management**: Environment variables
4. **Rate Limiting**: Da implementare per produzione

### Best Practices

- Non committare credenziali in git
- Usare `.env` per configurazione locale
- Validare input utente prima di processing
- Limitare dimensione upload file

---

## Deployment

### Requirements

```bash
# System dependencies
- Python 3.10+
- MongoDB 5.0+
- Redis 6.0+
- Ollama (per LLM locale)

# Python packages
pip install -r requirements.txt
```

### Setup Locale

```bash
# 1. Start MongoDB
mongod --dbpath /path/to/data

# 2. Start Redis
redis-server

# 3. Start Ollama
ollama serve
ollama pull llama3

# 4. Start Application
streamlit run presentation/notebook_page.py
```

### Docker (Futuro)

Containerizzazione per deployment semplificato:
- Container per app Python
- Container MongoDB
- Container Redis
- Container Ollama

---

## Roadmap

### Features in Sviluppo

- [ ] Cancellazione selettiva documenti
- [ ] Gestione permessi utenti
- [ ] Export notebook (PDF, Markdown)
- [ ] Statistiche utilizzo

### Miglioramenti Tecnici

- [ ] Containerizzazione Docker
- [ ] CI/CD pipeline
- [ ] Monitoring e logging
- [ ] API REST per integrazione

---

## Contribuire

### Setup Ambiente Sviluppo

```bash
# Clone repo
git clone https://github.com/minicla03/Q-AmodelAI.git

# Virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run tests
python -m pytest test/
```

### Code Style

- PEP 8 per Python
- Docstrings per funzioni pubbliche
- Type hints dove possibile

---

## Contatti & Supporto

Per domande o supporto:
- **GitHub Issues**: [Q-AmodelAI Issues](https://github.com/minicla03/Q-AmodelAI/issues)
- **Maintainer**: minicla03

---

*Documento aggiornato: Novembre 2025*
